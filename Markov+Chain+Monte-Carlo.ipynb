{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Monte-Carlo (MCMC) #\n",
    "Author: Harold Soh\n",
    "Date: 17 March 2020\n",
    "\n",
    "Code to accompany Lecture 9 on sampling and MCMC.\n",
    "\n",
    "A large part of this tutorial will be on estimating integrals which are **intractable** and/or have no closed form solution. In particular, we are often interested in estimating **expectations** $$\\mathbb{E}_{x\\sim p(x)}[f(x)]$$ but where $p(x)$ is difficult to sample from. In general, we will assume that $p(z)$ is known up to the normalization constant:\n",
    "$$p(x) = \\frac{1}{C}\\widehat{p}(x)$$\n",
    "In other words, we know $\\widehat{p}$ but not $C$ ($C$ is usually a difficult integral)\n",
    "\n",
    "*Note:* Code written to emphasize readability, not efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as random\n",
    "from numpy import log, exp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy as sp\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import autocorrelation_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating $\\mathbb{E}_{x}[f(x)]$ via Monte-Carlo##\n",
    "\n",
    "Given $f(x)$ that can be very complex, we want to compute $\\mathbb{E}_{x\\sim\\mathcal{N}}[f(x)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.cos(x)*(x**(3/3))\n",
    "\n",
    "xs = np.arange(-10,10,0.01)\n",
    "plt.plot(xs, f(xs), label='$f(x)$')\n",
    "_ = plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normpdf = stats.norm(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "x = normpdf.rvs(N)\n",
    "\n",
    "estimate = np.mean(f(x))\n",
    "print(\"Estimated expectation: \", estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But is this a good estimate? \n",
    "\n",
    "Also, what if I can't sample from $p(x)$ ? What if $p(x)$ didn't have a nice closed form expression like the normal distribution?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating $\\pi$ : Monte-Carlo style##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotCircle(n=200):\n",
    "    d = 2*np.pi/n\n",
    "    x = np.cos(np.arange(0,np.pi/2 + 0.01,d))\n",
    "    y = np.sin(np.arange(0,np.pi/2 + 0.01,d))   \n",
    "    plt.plot(x,y)\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "\n",
    "def estimatePi(N=1000, boxsize=1.0, doplot=True):\n",
    "    \n",
    "    # randomly sample N points in the box\n",
    "    x = random.uniform(0, boxsize, N)\n",
    "    y = random.uniform(0, boxsize, N)\n",
    "\n",
    "    # check if the points are in the circle\n",
    "    t = x**2 + y**2 <= 1\n",
    "\n",
    "    ic = np.where(t == True)[0] #inside indices\n",
    "    oc = np.where(t == False)[0] #outside indices\n",
    "    \n",
    "    # compute the area, \n",
    "    # for r = 1, this is also our estimate for pi \n",
    "    # since pi*r^2 = pi when r = 1\n",
    "    Nin = ic.shape[0]\n",
    "    pi_est = 4*(Nin/N)*((boxsize)**2)\n",
    "    \n",
    "    if doplot:\n",
    "        plt.scatter(x[ic],y[ic], c='green')\n",
    "        plt.scatter(x[oc],y[oc], c='red', marker='.')\n",
    "    \n",
    "    return pi_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCircle()\n",
    "pi_est = estimatePi(N=1000, boxsize=1.0)\n",
    "print(\"Estimate for pi:\", pi_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot how the  error from the  true pi \n",
    "# changes as we increase the number of samples\n",
    "ns = [10,50, 100, 500, 1000, 5000, 10000, 50000, 100000]\n",
    "err = np.zeros(len(ns))\n",
    "errvar = np.zeros(len(ns))\n",
    "for i in range(len(ns)):\n",
    "    n = ns[i]\n",
    "    pij = np.zeros(100)\n",
    "    for j in range(100):\n",
    "        pij[j] = estimatePi(N=n, boxsize=1.0,doplot=False)\n",
    "    err[i] = np.mean(np.abs(pij - np.pi))\n",
    "    errvar[i] = np.var(np.abs(pij - np.pi))\n",
    "\n",
    "plt.errorbar(ns, err, yerr=errvar, marker='x')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"Num samples\")\n",
    "plt.ylabel(\"Absolute Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distribution of estimates\n",
    "M = 10000\n",
    "pis = [estimatePi(N=10000, boxsize=1.0, doplot=False) for i in range(M)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = plt.hist(pis, bins=15)\n",
    "print(\"mean: %f, variance: %f\"%(np.mean(pis), np.var(pis)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling  ##\n",
    "\n",
    "Estimating the Expectation of a Gamma Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(x | a,b) = \\mathrm{Gamma}(x|a,b) = \\frac{1}{\\Gamma(a)}b^a x^{a-1} \\exp(-bx)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "def GammaUnnorm(x, a=1.99, b=1):\n",
    "    return np.nan_to_num((b**a) * (x**(a-1)) * np.exp(-b*x))\n",
    "\n",
    "def Gamma(x, a=1.99, b=1):\n",
    "    return GammaUnnorm(x, a=a, b=b)/sp.special.gamma(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the unnormalized gamma distribution\n",
    "a = 2.5\n",
    "b = 1\n",
    "x  = np.arange(0,10, 0.01)\n",
    "phat = GammaUnnorm(x, a=a, b=b)\n",
    "plt.plot(x, phat , 'b-', lw=1, label='Unnormalized Gamma')\n",
    "\n",
    "phat = Gamma(x, a=a, b=b)\n",
    "plt.plot(x, phat , 'r-', lw=1, label='Gamma')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estimation with a Normal proposal##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def rejSamplingDemo(a,b, qpdf, k, N=10000):\n",
    "    \n",
    "    x = qpdf.rvs(size=N)\n",
    "    u = random.uniform(0,1,N)\n",
    "\n",
    "    t = u < GammaUnnorm(x, a=a, b=b)/(k*qpdf.pdf(x)) \n",
    "\n",
    "    ic = np.where(t == True)[0] #inside indices\n",
    "\n",
    "    # compute Expectation\n",
    "    estmean = np.mean(x[ic])\n",
    "    return estmean, x[ic], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate expectation of a distribution\n",
    "# we'll estimate a Gamma with parameters a, b\n",
    "truemean = a/b # here,  the true value is a/b\n",
    "\n",
    "N = 100000\n",
    "normpdf = stats.norm(0,1)\n",
    "k = 10\n",
    "estmean, xs = rejSamplingDemo(a,b, normpdf, k, N=N)\n",
    "print(\"Estimated: %g (True: %g)\"%(estmean, truemean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm.. something went wrong. The estimated mean is far from the true mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot our samples! \n",
    "plt.plot(np.arange(0,10, 0.01), Gamma(np.arange(0,10, 0.01), a, b) , 'b-', lw=1, label='Gamma')\n",
    "plt.hist(xs, bins=20, density=True)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The samples don't look like they come from the Gamma! What went wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try  plotting out the two graphs\n",
    "x  = np.arange(0,10, 0.01)\n",
    "phat = GammaUnnorm(x,a,b)\n",
    "plt.plot(x, phat , 'b-', lw=1, label='Unnormalized Gamma')\n",
    "\n",
    "plt.plot(x, k*normpdf.pdf(x), 'g-', lw=1, label='kQ')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try  plotting out the two graphs in log scale\n",
    "x  = np.arange(0,10, 0.01)\n",
    "phat = GammaUnnorm(x,a,b)\n",
    "plt.semilogy(x, phat , 'b-', lw=1, label='Unnormalized Gamma')\n",
    "\n",
    "plt.semilogy(x, k*normpdf.pdf(x), 'g-', lw=1, label='kQ')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it looks  like the $\\mathcal{N}(0,1)$ was the wrong proposal distribution $q$ to use! \n",
    "\n",
    "We'll turn to the  Cauchy distribution which has \"fatter\" tails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Estimation with a Cauchy proposal##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot this out to be sure. \n",
    "x  = np.arange(0,10, 0.01)\n",
    "phat = GammaUnnorm(x)\n",
    "plt.plot(x, phat , 'b-', lw=1, label='Unnormalized Gamma')\n",
    "\n",
    "k = 5.0 # set this to make kq larger than phat\n",
    "cauchypdf = stats.cauchy(loc = a-1, scale=2*a-1)\n",
    "plt.semilogy(x, k*cauchypdf.pdf(x), 'g-', lw=1, label='kQ (Cauchy)')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try a Cauchy distribution.\n",
    "N = 10000\n",
    "estmean, xs = rejSamplingDemo(a,b,cauchypdf, k, N=N)\n",
    "print(\"Estimated: %g (True: %g)\"%(estmean, truemean))\n",
    "# Let's plot our samples! \n",
    "plt.plot(np.arange(0,10, 0.01), \n",
    "         Gamma(np.arange(0,10, 0.01), a, b) , \n",
    "         'b-', lw=1, label='Gamma')\n",
    "freqs = plt.hist(xs, bins=20, density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Acceptance rate: \", len(xs)/N )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance Sampling #\n",
    "\n",
    "Again, we'll try to estimate the mean of the Gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impSamplingDemo(a,b, qpdf, N=10000):\n",
    "    \n",
    "    x = qpdf.rvs(size=N)\n",
    "    \n",
    "    # compute importance weights\n",
    "    wl = GammaUnnorm(x,a,b)/qpdf.pdf(x)\n",
    "    wl = wl / np.sum(wl)\n",
    "\n",
    "    # compute Expectation\n",
    "    estmean = np.sum(x*wl)\n",
    "    return estmean, x, wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate expectation of a distribution\n",
    "# we'll estimate a Gamma with parameters a, b\n",
    "truemean = a/b # here,  the true value is a/b\n",
    "\n",
    "N = 100000\n",
    "estmean, xs, wl = impSamplingDemo(a,b, cauchypdf, N=N)\n",
    "print(\"Estimated: %g (True: %g)\"%(estmean, truemean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the mean and variances of running rejection/importance\n",
    "# sampling many times\n",
    "N = 50 # number of samples drawn from proposal\n",
    "M = 1000 # number of repetitions of sampling procedure\n",
    "\n",
    "rejmeans =  [rejSamplingDemo(a,b,cauchypdf, k, N=N)[0] for  i in range(M)]\n",
    "impmeans =  [impSamplingDemo(a,b,cauchypdf, N=N)[0] for  i in range(M)]\n",
    "\n",
    "print(\"Rejection Sampling Mean (Variance) : %g (%g)\"%(np.mean(rejmeans), np.var(rejmeans)))\n",
    "print(\"Importance Sampling Mean (Variance): %g (%g)\"%(np.mean(impmeans), np.var(impmeans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back  to a Normal Proposal Distribution ###\n",
    "What if we tried a normal proposal again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate expectation of a distribution\n",
    "# we'll estimate a Gamma with parameters a, b\n",
    "truemean = a/b # here,  the true value is a/b\n",
    "\n",
    "# let's first try a normal(0,1)  distribution.\n",
    "N = 10000\n",
    "estmean, xs, wl = impSamplingDemo(a,b, normpdf, N=N)\n",
    "print(\"Estimated: %g (True: %g)\"%(estmean, truemean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impmeans_normal =  [impSamplingDemo(a,b,normpdf, N=N)[0] for  i in range(M)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"IS using Cauchy: Mean (Variance): %g (%g)\"%(np.mean(impmeans), np.var(impmeans)))\n",
    "print(\"IS using Normal: Mean (Variance): %g (%g)\"%(np.mean(impmeans_normal), np.var(impmeans_normal)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot how the  error from the  true pi \n",
    "# changes as we increase the number of samples\n",
    "def getErrs(ns, qpdf):\n",
    "    \n",
    "    err = np.zeros(len(ns))\n",
    "    errvar = np.zeros(len(ns))\n",
    "    M = 100 # internal samples\n",
    "    for i in range(len(ns)):\n",
    "        n = ns[i]\n",
    "        mj = np.zeros(M)\n",
    "        for j in range(M):\n",
    "            mj[j] = impSamplingDemo(a,b,qpdf, N=n)[0] \n",
    "        err[i] = np.mean(np.abs(mj - truemean))\n",
    "        errvar[i] = np.var(np.abs(mj - truemean))\n",
    "        \n",
    "    return err, errvar\n",
    "\n",
    "ns = [10,50, 100, 500, 1000, 5000, 10000, 50000]\n",
    "err_norm, errvar_norm = getErrs(ns, normpdf)        \n",
    "err_cauchy, errvar_cauchy = getErrs(ns, cauchypdf)\n",
    "\n",
    "plt.errorbar(ns, err_cauchy, yerr=errvar_cauchy, marker='+', label=\"cauchy\")\n",
    "plt.errorbar(ns, err_norm, yerr=errvar_norm, marker='x', label=\"normal\")\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"Num samples\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metropolis-Hasting Algorithm ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll experiment with the Metropolis-Hasting algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# phat is the unnormalized distribution\n",
    "# qpdf is the proposal distribution pdf\n",
    "# qsample is a means of sampling from q\n",
    "# N is the number of samples we want to draw\n",
    "# T is the interval at which we record a sample.\n",
    "\n",
    "def MCMCDemo(x, phat, qpdf, qsample, N, T=100):\n",
    "    xs = np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        for t in range(T): # record after T samples\n",
    "            u = np.random.uniform(0,1)\n",
    "            xc = qsample(x)\n",
    "            if u < min(1, np.nan_to_num((phat(xc)*qpdf(x,xc)) / (phat(x)*qpdf(xc,x)))):\n",
    "                x = xc\n",
    "        xs[i] = x\n",
    "\n",
    "    estmean = np.mean(xs)\n",
    "    return estmean, xs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# set up our distributions\n",
    "phat = lambda x : GammaUnnorm(x, a=a, b=b)\n",
    "qpdf = lambda x, mu : stats.norm.pdf(x, mu, 1.0)\n",
    "qsample = lambda mu : stats.norm.rvs(mu,1.0)\n",
    "\n",
    "# our parameters\n",
    "x = 0.0 # the initial x\n",
    "N = 1000 # number of samples\n",
    "\n",
    "Nburnin = 1000\n",
    "T = 50\n",
    "\n",
    "# start with burnin\n",
    "MCMCDemo(0, phat, qpdf, qsample, N=Nburnin, T=1)\n",
    "\n",
    "# sample\n",
    "estmean, xs = MCMCDemo(x, phat, qpdf, qsample, N=N, T=T)\n",
    "print(\"Estimated: %g (True: %g)\"%(estmean, truemean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot our samples! \n",
    "plt.plot(np.arange(0,10, 0.01), \n",
    "         Gamma(np.arange(0,10, 0.01), a, b) , \n",
    "         'b-', lw=1, label='Gamma')\n",
    "freqs = plt.hist(xs, bins=20, density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis\n",
    "autocorrelation_plot(pd.Series(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from a GMM ### \n",
    "Let's try a multimodal distribution, e.g., a GMM! Of course, a GMM is pretty easy to sample from; this is purely for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMMUnnorm(x, pi, normpdfs):\n",
    "    logp = 0\n",
    "    for i in range(pi.shape[0]):\n",
    "        logp += exp(log(pi[i]) + normpdfs[i].logpdf(x))\n",
    "    return logp\n",
    "\n",
    "pi = np.array([0.4, 0.6])\n",
    "normpdfs = np.array([stats.norm(-1.0,0.5), stats.norm(2.0,1.0)])\n",
    "truemeanGMM =  pi[0]*normpdfs[0].mean() + pi[1]*normpdfs[1].mean()\n",
    "\n",
    "x = np.arange(-3.0, 5.0, 0.01)\n",
    "ps = GMMUnnorm(x, pi, normpdfs)\n",
    "plt.plot(x,ps)\n",
    "\n",
    "\n",
    "phat = lambda x : GMMUnnorm(x, pi, normpdfs)\n",
    "qpdf = lambda x, mu : stats.norm.pdf(x, mu, 1)\n",
    "qsample = lambda mu : stats.norm.rvs(mu,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our parameters\n",
    "x = 0.0 # the initial x\n",
    "N = 1000 # number of samples\n",
    "\n",
    "Nburnin = 1000\n",
    "T = 50\n",
    "\n",
    "# start with burnin\n",
    "MCMCDemo(0, phat, qpdf, qsample, N=Nburnin, T=1)\n",
    "\n",
    "# sample\n",
    "estmean, xs = MCMCDemo(x, phat, qpdf, qsample, N=N, T=T)\n",
    "\n",
    "print(\"Estimated: %g (True: %g)\"%(estmean, truemeanGMM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's plot our samples! \n",
    "z = np.arange(-3.0, 5.0, 0.01)\n",
    "plt.plot(z, phat(z), \n",
    "         'b-', lw=1, label='GMM')\n",
    "freqs = plt.hist(xs, bins=20, density=True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis\n",
    "autocorrelation_plot(pd.Series(xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Slides ##\n",
    "\n",
    "But **why** does MCMC work? For that, we need some theory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
